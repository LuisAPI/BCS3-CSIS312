{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\luis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\luis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\luis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\luis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in c:\\users\\luis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\luis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Luis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Luis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Luis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Luis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk - wordnet and lexical database: setting up WordNet in NLTK\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "#for wordnet with different language\n",
    "nltk.download('omw-1.4')\n",
    "#for tokenization\n",
    "nltk.download('punkt')\n",
    "#POS tagger part of speech\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sentence: ['The', 'riverbank', 'was', 'overflowing', '.']\n",
      "POS tags: [('The', 'DT'), ('riverbank', 'NN'), ('was', 'VBD'), ('overflowing', 'VBG'), ('.', '.')]\n",
      "Synset('savings_bank.n.02')\n",
      "Sentence: The riverbank was overflowing.\n",
      "Best sense of 'bank': Synset('savings_bank.n.02')\n",
      "Definition: a container (usually with a slot in the top) for keeping money at home\n",
      "Tokenized sentence: ['He', 'withdrew', 'money', 'from', 'the', 'bank', '.']\n",
      "POS tags: [('He', 'PRP'), ('withdrew', 'VBD'), ('money', 'NN'), ('from', 'IN'), ('the', 'DT'), ('bank', 'NN'), ('.', '.')]\n",
      "Synset('savings_bank.n.02')\n",
      "Sentence: He withdrew money from the bank.\n",
      "Best sense of 'bank': Synset('savings_bank.n.02')\n",
      "Definition: a container (usually with a slot in the top) for keeping money at home\n"
     ]
    }
   ],
   "source": [
    "#implement Lesk Algo - is simple knowledge-based WSD method - lesk()\n",
    "from nltk.wsd import lesk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "#example sentence\n",
    "#sentence = \"I deposited money at the bank.\"\n",
    "sentences = [\n",
    "    \"The riverbank was overflowing.\",\n",
    "    \"He withdrew money from the bank.\"\n",
    "]\n",
    "#disambiguate the word 'bank'\n",
    "# sense = lesk(nltk.word_tokenize(sentence), 'bank')\n",
    "\n",
    "# print(f\"Best sense of 'bank': {sense}\")\n",
    "# print(f\"Definition: {sense.definition()}\")\n",
    "\n",
    "# Define a function to manually find the appropriate sense\n",
    "def get_best_sense(word, context):\n",
    "    synsets = wn.synsets(word)\n",
    "\n",
    "    print(f\"All possible senses for '{word}': \")\n",
    "    for i, syn in enumerate(synsets, 1):\n",
    "        print(f\"{i}. {syn.name()}: {syn.definition()}\")\n",
    "    \n",
    "    # Based on context, manually select the appropriate sense\n",
    "    if \"river\" in context or \"overflowing\" in context:\n",
    "        # Select the sense related to the geographical feature (river bank)\n",
    "            # Synset index for 'bank' as a riverbank\n",
    "        selected_sense = synsets[0]\n",
    "    elif \"money\" in context or \"withdrew\" in context:\n",
    "        # Select the financial institution sense\n",
    "        # Synset index for 'bank' as a financial institution\n",
    "        selected_sense = synsets[3]\n",
    "    else:\n",
    "        selected_sense = None\n",
    "    \n",
    "    return selected_sense\n",
    "\n",
    "# Loop through each sentence\n",
    "for sentence in sentences:\n",
    "    # Tokenize the sentence\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "    # Use manual disambiguation based on the context\n",
    "    best_sense = get_best_sense('bank', sentence)\n",
    "\n",
    "    if best_sense:\n",
    "        print(f\"\\nSentence: {sentence}\")\n",
    "        print(f\"Best sense of 'bank': {best_sense.name()}\")\n",
    "        print(f\"Definition: {best_sense.definition()}\")\n",
    "    else:\n",
    "        print(f\"No suitable sense found for 'bank' in the sentence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Mini Activity - WSD\n",
    "\n",
    "Activity: Building a Simple WSD System (1 hour)  \n",
    "Objective: Students will implement a basic WSD model using Python and apply it to a dataset of sentences with ambiguous words.\n",
    "\n",
    "Instructions:  \n",
    "Dataset Preparation:\n",
    "\n",
    "Provide a dataset containing sentences with ambiguous words like \"bank,\" \"plant,\" \"bark,\" etc.  \n",
    "Task 1: Implement the Lesk Algorithm\n",
    "\n",
    "Use the Lesk algorithm in Python to disambiguate each ambiguous word in the dataset.  \n",
    "Task 2: Compare Results with Gold Standard:\n",
    "\n",
    "Compare the algorithmâ€™s output with human-labeled correct senses.  \n",
    "Task 3: Evaluate Performance:\n",
    "\n",
    "Measure accuracy using metrics like precision, recall, and F1 score.  \n",
    "Discuss areas of improvement in the algorithm.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
