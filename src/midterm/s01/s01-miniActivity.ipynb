{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMMfZ6bn5F835FfbI90MsZk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 240822 - Mini Activity\n","\n","- Type: Discussion\n","- Max score: 100\n","- Category: Class Participation\n","- Start: Aug 22, 3:00 pm\n","- Due: Sep 7, 6:00 pm\n","- Allow late submissions: ‚ùå\n","\n","Please refer to the Lesson and Discussion for the instruction.\n","\n","Screenshot your code and result and write your insights.\n","\n","First 5 submitted without error - 100  \n","Second 5 submitted without error - 90  \n","The rest of submission without error - 85  \n","Late submission without error - 75  \n","No submission and with an error is 0"],"metadata":{"id":"2bbKfA0hmJcy"}},{"cell_type":"code","source":["import nltk\n","import spacy\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from spacy.lang.en import English\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.pipeline import make_pipeline\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","nlp = English()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0cli-47p5qos","executionInfo":{"status":"ok","timestamp":1725613793403,"user_tz":-480,"elapsed":10260,"user":{"displayName":"Luis Anton Imperial","userId":"11563317455878916196"}},"outputId":"b2747412-4e89-4d2c-f994-28057cbd29a8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","source":["texts = [\n","    \"The movie was fantastic, I loved every moment of it\",\n","    \"The food was terrible, I would never eat there again\",\n","    \"I had a great time at the concert\",\n","    \"The service at the restaurant was horrible\",\n","    \"I really enjoyed the book\",\n","    \"The hotel room was dirty and uncomfortable\",\n","    \"I am very satisfied with my purchase\",\n","    \"The delivery was late and the package was damaged\",\n","    \"The customer support was very helpful\",\n","    \"I am disappointed with the quality of the product\"\n","         ]\n","labels = ['Positive',\n","          'Negative',\n","          'Positive',\n","          'Negative',\n","          'Positive',\n","          'Negative',\n","          'Positive',\n","          'Negative',\n","          'Positive',\n","          'Negative'\n","]"],"metadata":{"id":"37SZVG1O52db","executionInfo":{"status":"ok","timestamp":1725613803839,"user_tz":-480,"elapsed":319,"user":{"displayName":"Luis Anton Imperial","userId":"11563317455878916196"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["new_texts_to_analyze = 10"],"metadata":{"id":"J10-HcBTnXso","executionInfo":{"status":"ok","timestamp":1725614104868,"user_tz":-480,"elapsed":345,"user":{"displayName":"Luis Anton Imperial","userId":"11563317455878916196"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["model1 = make_pipeline(CountVectorizer(), MultinomialNB())\n","model1.fit(texts, labels)\n","\n","for statement in texts:\n","    print(\"Text to analyze:\", statement)\n","    token = word_tokenize(statement)\n","    print(\"Tokenized text:\", token)\n","\n","    prediction = model1.predict([statement])\n","    print(f\"Predicted sentiment using CountVectorizer:\", prediction[0], end=\"\\n\\n\")\n","\n","i = 0\n","while i < new_texts_to_analyze:\n","  user_input = input(\"Enter a text: \")\n","  if user_input == \"no\":\n","    break\n","\n","  prediction = model1.predict([user_input])\n","  print(\"Predicted Sentiment using CountVectorizer:\", prediction[0])\n","  i += 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ow0xmxkqmPtP","executionInfo":{"status":"ok","timestamp":1725614442357,"user_tz":-480,"elapsed":328636,"user":{"displayName":"Luis Anton Imperial","userId":"11563317455878916196"}},"outputId":"5fce1cd2-e932-4cfd-c4de-a190cceaaaa7"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Text to analyze: The movie was fantastic, I loved every moment of it\n","Tokenized text: ['The', 'movie', 'was', 'fantastic', ',', 'I', 'loved', 'every', 'moment', 'of', 'it']\n","Predicted sentiment using CountVectorizer: Positive\n","\n","Text to analyze: The food was terrible, I would never eat there again\n","Tokenized text: ['The', 'food', 'was', 'terrible', ',', 'I', 'would', 'never', 'eat', 'there', 'again']\n","Predicted sentiment using CountVectorizer: Negative\n","\n","Text to analyze: I had a great time at the concert\n","Tokenized text: ['I', 'had', 'a', 'great', 'time', 'at', 'the', 'concert']\n","Predicted sentiment using CountVectorizer: Positive\n","\n","Text to analyze: The service at the restaurant was horrible\n","Tokenized text: ['The', 'service', 'at', 'the', 'restaurant', 'was', 'horrible']\n","Predicted sentiment using CountVectorizer: Negative\n","\n","Text to analyze: I really enjoyed the book\n","Tokenized text: ['I', 'really', 'enjoyed', 'the', 'book']\n","Predicted sentiment using CountVectorizer: Positive\n","\n","Text to analyze: The hotel room was dirty and uncomfortable\n","Tokenized text: ['The', 'hotel', 'room', 'was', 'dirty', 'and', 'uncomfortable']\n","Predicted sentiment using CountVectorizer: Negative\n","\n","Text to analyze: I am very satisfied with my purchase\n","Tokenized text: ['I', 'am', 'very', 'satisfied', 'with', 'my', 'purchase']\n","Predicted sentiment using CountVectorizer: Positive\n","\n","Text to analyze: The delivery was late and the package was damaged\n","Tokenized text: ['The', 'delivery', 'was', 'late', 'and', 'the', 'package', 'was', 'damaged']\n","Predicted sentiment using CountVectorizer: Negative\n","\n","Text to analyze: The customer support was very helpful\n","Tokenized text: ['The', 'customer', 'support', 'was', 'very', 'helpful']\n","Predicted sentiment using CountVectorizer: Positive\n","\n","Text to analyze: I am disappointed with the quality of the product\n","Tokenized text: ['I', 'am', 'disappointed', 'with', 'the', 'quality', 'of', 'the', 'product']\n","Predicted sentiment using CountVectorizer: Negative\n","\n","Enter a text: I was so happy with the textbook\n","Predicted Sentiment using CountVectorizer: Negative\n","Enter a text: They claimed to be helpful, but they weren't\n","Predicted Sentiment using CountVectorizer: Positive\n","Enter a text: The service was late for me\n","Predicted Sentiment using CountVectorizer: Negative\n","Enter a text: The purchase didn't arrive at all\n","Predicted Sentiment using CountVectorizer: Positive\n","Enter a text: Terrible. Horrible. Those are the only words I can use\n","Predicted Sentiment using CountVectorizer: Negative\n","Enter a text: I'm never going back\n","Predicted Sentiment using CountVectorizer: Negative\n","Enter a text: My family loved every bit of it!\n","Predicted Sentiment using CountVectorizer: Positive\n","Enter a text: Poor customer support. Awful product with an awful team behind it\n","Predicted Sentiment using CountVectorizer: Positive\n","Enter a text: The hotel wasted our time with disappointing service\n","Predicted Sentiment using CountVectorizer: Negative\n","Enter a text: Amazing, enjoyable movie, matched by none other\n","Predicted Sentiment using CountVectorizer: Positive\n"]}]},{"cell_type":"code","source":["model2 = make_pipeline(TfidfVectorizer(), MultinomialNB())\n","model2.fit(texts, labels)\n","\n","for statement in texts:\n","    print(\"Text to analyze:\", statement)\n","    token = word_tokenize(statement)\n","    print(\"Tokenized text:\", token)\n","\n","    prediction = model2.predict([statement])\n","    print(f\"Predicted sentiment using TfidfVectorizer:\", prediction[0], end=\"\\n\\n\")\n","\n","print(\"-----\")\n","print(\"NEW TEXTS FOLLOW\")\n","print(\"-----\")\n","\n","i = 0\n","while i < new_texts_to_analyze:\n","  user_input = input(\"Enter a text: \")\n","  if user_input == \"no\":\n","    break\n","\n","  prediction = model2.predict([user_input])\n","  print(\"Predicted Sentiment using TdidfVectorizer:\", prediction[0], end=\"\\n\\n\")\n","  i += 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rg6zJWbAmelY","executionInfo":{"status":"ok","timestamp":1725614571254,"user_tz":-480,"elapsed":72991,"user":{"displayName":"Luis Anton Imperial","userId":"11563317455878916196"}},"outputId":"d84d7a9e-9593-4f09-afed-6ee6c24a9596"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Text to analyze: The movie was fantastic, I loved every moment of it\n","Tokenized text: ['The', 'movie', 'was', 'fantastic', ',', 'I', 'loved', 'every', 'moment', 'of', 'it']\n","Predicted sentiment using TfidfVectorizer: Positive\n","\n","Text to analyze: The food was terrible, I would never eat there again\n","Tokenized text: ['The', 'food', 'was', 'terrible', ',', 'I', 'would', 'never', 'eat', 'there', 'again']\n","Predicted sentiment using TfidfVectorizer: Negative\n","\n","Text to analyze: I had a great time at the concert\n","Tokenized text: ['I', 'had', 'a', 'great', 'time', 'at', 'the', 'concert']\n","Predicted sentiment using TfidfVectorizer: Positive\n","\n","Text to analyze: The service at the restaurant was horrible\n","Tokenized text: ['The', 'service', 'at', 'the', 'restaurant', 'was', 'horrible']\n","Predicted sentiment using TfidfVectorizer: Negative\n","\n","Text to analyze: I really enjoyed the book\n","Tokenized text: ['I', 'really', 'enjoyed', 'the', 'book']\n","Predicted sentiment using TfidfVectorizer: Positive\n","\n","Text to analyze: The hotel room was dirty and uncomfortable\n","Tokenized text: ['The', 'hotel', 'room', 'was', 'dirty', 'and', 'uncomfortable']\n","Predicted sentiment using TfidfVectorizer: Negative\n","\n","Text to analyze: I am very satisfied with my purchase\n","Tokenized text: ['I', 'am', 'very', 'satisfied', 'with', 'my', 'purchase']\n","Predicted sentiment using TfidfVectorizer: Positive\n","\n","Text to analyze: The delivery was late and the package was damaged\n","Tokenized text: ['The', 'delivery', 'was', 'late', 'and', 'the', 'package', 'was', 'damaged']\n","Predicted sentiment using TfidfVectorizer: Negative\n","\n","Text to analyze: The customer support was very helpful\n","Tokenized text: ['The', 'customer', 'support', 'was', 'very', 'helpful']\n","Predicted sentiment using TfidfVectorizer: Positive\n","\n","Text to analyze: I am disappointed with the quality of the product\n","Tokenized text: ['I', 'am', 'disappointed', 'with', 'the', 'quality', 'of', 'the', 'product']\n","Predicted sentiment using TfidfVectorizer: Negative\n","\n","-----\n","NEW TEXTS FOLLOW\n","-----\n","Enter a text: I was so happy with the textbook\n","Predicted Sentiment using TdidfVectorizer: Negative\n","\n","Enter a text: They claimed to be helpful, but they weren't\n","Predicted Sentiment using TdidfVectorizer: Positive\n","\n","Enter a text: The service was late for me\n","Predicted Sentiment using TdidfVectorizer: Negative\n","\n","Enter a text: The purchase didn't arrive at all\n","Predicted Sentiment using TdidfVectorizer: Positive\n","\n","Enter a text: Terrible. Horrible. Those are the only words I can use\n","Predicted Sentiment using TdidfVectorizer: Negative\n","\n","Enter a text: I'm never going back\n","Predicted Sentiment using TdidfVectorizer: Negative\n","\n","Enter a text: My family loved every bit of it!\n","Predicted Sentiment using TdidfVectorizer: Positive\n","\n","Enter a text: Poor customer support. Awful product with an awful team behind it\n","Predicted Sentiment using TdidfVectorizer: Positive\n","\n","Enter a text: The hotel wasted our time with disappointing service\n","Predicted Sentiment using TdidfVectorizer: Negative\n","\n","Enter a text: Amazing, enjoyable movie, matched by none other\n","Predicted Sentiment using TdidfVectorizer: Positive\n","\n"]}]}]}