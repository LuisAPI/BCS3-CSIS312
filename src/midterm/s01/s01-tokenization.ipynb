{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN/1OoprCCqYGq0Mozt/VJx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tKAtWQffedeh","executionInfo":{"status":"ok","timestamp":1725494483674,"user_tz":-480,"elapsed":8537,"user":{"displayName":"Luis Anton Imperial","userId":"11563317455878916196"}},"outputId":"7c2eb7b3-c7b5-445c-c964-1b92dfe0f521"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.6)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.8.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.8.0)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"]}],"source":["!pip install nltk spacy"]},{"cell_type":"markdown","source":["NLTK - Natural Language Toolkit\n","- comprehensive library in NLP that provides easy to use interfaces for over 500 corpora and lexical analysis such as wordNet\n","-- classification\n","-- tokenization\n","-- stemming\n","-- tagging\n","-- parsing\n","-- semantic reasoning\n","- corpora\n","-- training and testing model SpaCy\n","- advanced library for NLP\n","-- for fast and efficient processing"],"metadata":{"id":"Wcca2pf1gP1e"}},{"cell_type":"code","source":["import nltk\n","import spacy\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","#stopwords are common words (is, and, the)\n","from spacy.lang.en import English\n","\n","# Download NLTK resources\n","nltk.download('punkt')\n","# punkt is a tokenizer model used for splitting text into sentences (sentence tokenization)\n","# from sentences into words (word tokenization)\n","nltk.download('stopwords')\n","\n","# load SpaCy model\n","nlp = English()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aHQguOByhOgq","executionInfo":{"status":"ok","timestamp":1725495374577,"user_tz":-480,"elapsed":11235,"user":{"displayName":"Luis Anton Imperial","userId":"11563317455878916196"}},"outputId":"5cda0322-e8ea-4175-a285-882c034d6ec4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","source":["text = \"This is a sample text\"\n","text1 = \"Nag-aaral ako sa La Salle and I am a computer science student\"\n","tokens = word_tokenize(text)\n","token1 = word_tokenize(text1)\n","print(\"Tokens using NLTK:\", tokens)\n","print(\"Tokens using NLTK:\", token1)"],"metadata":{"id":"YAdZuwSPjlDH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725496273870,"user_tz":-480,"elapsed":437,"user":{"displayName":"Luis Anton Imperial","userId":"11563317455878916196"}},"outputId":"25790c92-f703-4c5e-bd0e-ee82d0c79673"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokens using NLTK: ['This', 'is', 'a', 'sample', 'text']\n","Tokens using NLTK: ['Nag-aaral', 'ako', 'sa', 'La', 'Salle', 'and', 'I', 'am', 'a', 'computer', 'science', 'student']\n"]}]},{"cell_type":"code","source":["doc = nlp(text)\n","spacy_tokens = [token.text for token in doc]\n","print(\"Tokens using SpaCy:\", spacy_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_3yhb_pkl719","executionInfo":{"status":"ok","timestamp":1725496287868,"user_tz":-480,"elapsed":529,"user":{"displayName":"Luis Anton Imperial","userId":"11563317455878916196"}},"outputId":"e09f3142-2888-4a21-fdb7-1766a72996b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokens using SpaCy: ['This', 'is', 'a', 'sample', 'text']\n"]}]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","#CountVectorizer is a tool that converts a collection of text document info matrix\n","#token, it breaks down text into individual words for token)\n","#and it count how often (freq) each word appears in text\n","from sklearn.naive_bayes import MultinomialNB\n","#MultinomialNB - this is a Naive Bayes classifier for multinomially distribute data\n","#often used for the text classification - represents freq or counts\n","from sklearn.pipeline import make_pipeline\n","#make_pipeline it is a function used to create a pipeline that sequentially\n","#combine several processing steps into a single object\n","\n","#example data\n","texts = ['I love programming', 'I hate bugs', 'I adore my teacher',\n","         'Programming is great', 'I really enjoy solving problems',\n","         'Bugs are frustrating', 'I dislike errors', 'I cannot stand issues',\n","         'Coding is so much fun', 'I find programming to be amazing',\n","         'I dislike debugging']\n","labels = ['Positive', 'Negative', 'Neutral', 'Positive', 'Positive', 'Negative',\n","          'Negative', 'Negative', 'Positive', 'Positive', 'Negative']\n","\n","#create a pipeline for the classification\n","model = make_pipeline(CountVectorizer(), MultinomialNB())\n","model.fit(texts, labels)\n","\n","#accept user input\n","user_input = input(\"Enter a text: \")\n","\n","#predict the sentiment of the user input\n","prediction = model.predict([user_input])\n","print(\"Predicted Sentiment:\", prediction[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dVQyTBB7pJk3","executionInfo":{"status":"ok","timestamp":1725498009453,"user_tz":-480,"elapsed":7832,"user":{"displayName":"Luis Anton Imperial","userId":"11563317455878916196"}},"outputId":"30d57046-032c-4c0d-e790-1e7ef1166e0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter a text: I adore my teacher\n","Predicted Sentiment: Neutral\n"]}]},{"cell_type":"markdown","source":["## 240822 - Mini Activity\n","\n","- Type: Discussion\n","- Max score: 100\n","- Category: Class Participation\n","- Start: Aug 22, 3:00 pm\n","- Due: Sep 7, 6:00 pm\n","- Allow late submissions: ‚ùå\n","\n","Please refer to the Lesson and Discussion for the instruction.\n","\n","Screenshot your code and result and write your insights.\n","\n","First 5 submitted without error - 100  \n","Second 5 submitted without error - 90  \n","The rest of submission without error - 85  \n","Late submission without error - 75  \n","No submission and with an error is 0  "],"metadata":{"id":"_-JmRfhwzGko"}}]}